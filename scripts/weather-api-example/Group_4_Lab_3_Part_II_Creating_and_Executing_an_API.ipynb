{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CojT76QDBmhP"
   },
   "source": [
    "# Fetching Weather Data and Uploading to AWS S3\n",
    "\n",
    "This guide provides steps for fetching weather data using the OpenWeatherMap API and then uploading the data to an Amazon S3 bucket using Python.\n",
    "\n",
    "## Step 1: Obtain an API Key from OpenWeatherMap\n",
    "\n",
    "1. Register on the [OpenWeatherMap website](https://openweathermap.org/) and create an account.\n",
    "2. Find and copy the API key from your account dashboard.\n",
    "\n",
    "## Step 2: Write Python Function to Fetch Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IhtMAOMHBiyt"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import weather_key\n",
    "\n",
    "def get_weather_data(city, api_key):\n",
    "    base_url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {'q': city, 'appid': api_key}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(\"Failed to fetch weather data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGIMEi1-Bvbm"
   },
   "source": [
    "## Step 3: Set Up AWS Credentials for S3 Access\n",
    "* Install Boto3 using pip install boto3.\n",
    "* Configure AWS credentials (AWS Access Key ID and Secret Access Key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZW3uJbuB489",
    "outputId": "aebe3abe-9c4c-4927-e4d0-b83aba818bf7"
   },
   "outputs": [],
   "source": [
    "#!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: boto3\n",
      "Version: 1.34.40\n",
      "Summary: The AWS SDK for Python\n",
      "Home-page: https://github.com/boto/boto3\n",
      "Author: Amazon Web Services\n",
      "Author-email: \n",
      "License: Apache License 2.0\n",
      "Location: c:\\users\\ankit\\anaconda3\\envs\\dl38\\lib\\site-packages\n",
      "Requires: botocore, jmespath, s3transfer\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show Boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnn-pfSWCXfi"
   },
   "source": [
    "## Step 4: Write Python Function to Upload Data to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ja7gCT4CCVt4"
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def upload_to_s3(bucket_name, file_name, data):\n",
    "    s3 = boto3.client('s3',\n",
    "            aws_access_key_id=weather_key.aws_access_key_id, \n",
    "            aws_secret_access_key= weather_key.aws_secret_access_key, region_name=\"us-east-1\")\n",
    "    s3.put_object(Bucket=bucket_name, Key=file_name, Body=json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G795_fa1CcgS"
   },
   "source": [
    "## Step 5: Combine the Functions in a Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qObZbAK8Ce9C",
    "outputId": "05c3b5f4-c8d8-4dc7-9cad-cb833493f762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully to S3\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import weather_key\n",
    "importlib.reload(weather_key)\n",
    "\n",
    "# Main execution\n",
    "api_key = weather_key.api_key   # Replace with your API key\n",
    "city = \"London\"  # Replace with desired city\n",
    "bucket_name = \"lab03ankit\"  # Replace with your S3 bucket name\n",
    "file_name = \"weather_data.json\"\n",
    "\n",
    "try:\n",
    "    weather_data = get_weather_data(city, api_key)\n",
    "    upload_to_s3(bucket_name, file_name, weather_data)\n",
    "    print(\"Data uploaded successfully to S3\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlFDrpu_Co3T",
    "outputId": "62eba14a-296a-4d75-b03c-4506d47983fd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coord': {'lon': -0.1257, 'lat': 51.5085}, 'weather': [{'id': 803, 'main': 'Clouds', 'description': 'broken clouds', 'icon': '04d'}], 'base': 'stations', 'main': {'temp': 288.03, 'feels_like': 287.51, 'temp_min': 287.06, 'temp_max': 288.71, 'pressure': 1006, 'humidity': 74}, 'visibility': 10000, 'wind': {'speed': 4.63, 'deg': 220}, 'clouds': {'all': 75}, 'dt': 1712340715, 'sys': {'type': 2, 'id': 2075535, 'country': 'GB', 'sunrise': 1712294752, 'sunset': 1712342396}, 'timezone': 3600, 'id': 2643743, 'name': 'London', 'cod': 200}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "api_key = weather_key.api_key  # Replace with your actual API key\n",
    "city = \"London\"\n",
    "try:\n",
    "    weather_data = get_weather_data(city, api_key)\n",
    "    print(weather_data)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Groups to Convert JSON to CSV\n",
    "\n",
    "Step 1. Take the JSON output and convert it to a Dataframe using pandas\n",
    "Step 2. Now upload the CSV file to the 'lab-03' S3 bucket in the cloud with the following naming convention: <your group name>_weather_date_london_<datetimestamp>.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Uploaded Successfully to S3 Bucket.\n"
     ]
    }
   ],
   "source": [
    "###### INSERT CODE BELOW ####\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from io import StringIO\n",
    "import weather_key\n",
    "\n",
    "df = pd.json_normalize(weather_data)\n",
    "\n",
    "def upload_file_to_s3(dataframe, city):\n",
    "    s3 = boto3.client(\"s3\", aws_access_key_id=weather_key.aws_access_key_id, aws_secret_access_key=weather_key.aws_secret_access_key)\n",
    "    temp_df = StringIO()\n",
    "    df.to_csv(temp_df, header=True, index=False)\n",
    "    temp_df.seek(0)    \n",
    "    current_datetime = datetime.now().strftime(\"%Y%m%d%H%M%S\") \n",
    "    filename = f\"weather_data_{city}_{current_datetime}.csv\"  \n",
    "    s3.put_object(Bucket=\"lab03ankit\", Body=temp_df.getvalue(), Key=filename)\n",
    "    print(\"File Uploaded Successfully to S3 Bucket.\")\n",
    "\n",
    "upload_file_to_s3(df, \"london\")\n",
    "### END CODE ###"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

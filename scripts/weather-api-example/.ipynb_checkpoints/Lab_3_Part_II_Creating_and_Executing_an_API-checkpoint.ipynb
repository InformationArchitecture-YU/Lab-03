{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CojT76QDBmhP"
   },
   "source": [
    "# Fetching Weather Data and Uploading to AWS S3\n",
    "\n",
    "This guide provides steps for fetching weather data using the OpenWeatherMap API and then uploading the data to an Amazon S3 bucket using Python.\n",
    "\n",
    "## Step 1: Obtain an API Key from OpenWeatherMap\n",
    "\n",
    "1. Register on the [OpenWeatherMap website](https://openweathermap.org/) and create an account.\n",
    "2. Find and copy the API key from your account dashboard.\n",
    "\n",
    "## Step 2: Write Python Function to Fetch Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IhtMAOMHBiyt"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather_data(city, api_key):\n",
    "    base_url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {'q': city, 'appid': api_key}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(\"Failed to fetch weather data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGIMEi1-Bvbm"
   },
   "source": [
    "## Step 3: Set Up AWS Credentials for S3 Access\n",
    "* Install Boto3 using pip install boto3.\n",
    "* Configure AWS credentials (AWS Access Key ID and Secret Access Key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZW3uJbuB489",
    "outputId": "aebe3abe-9c4c-4927-e4d0-b83aba818bf7"
   },
   "outputs": [],
   "source": [
    "#!pip install boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnn-pfSWCXfi"
   },
   "source": [
    "## Step 4: Write Python Function to Upload Data to S3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ja7gCT4CCVt4"
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "def upload_to_s3(bucket_name, file_name, data):\n",
    "    with open('C:/Users/msi/OneDrive/Documents/GitHub/aws_credentials.json', 'r') as file:\n",
    "        credentials = json.load(file)\n",
    "\n",
    "    session = boto3.Session(\n",
    "        aws_access_key_id=credentials['AWS_ACCESS_KEY_ID'],\n",
    "        aws_secret_access_key=credentials['AWS_SECRET_ACCESS_KEY']\n",
    "    )\n",
    "    s3 = session.client('s3')\n",
    "    s3.put_object(Bucket=bucket_name, Key=file_name, Body=json.dumps(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G795_fa1CcgS"
   },
   "source": [
    "## Step 5: Combine the Functions in a Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qObZbAK8Ce9C",
    "outputId": "05c3b5f4-c8d8-4dc7-9cad-cb833493f762"
   },
   "outputs": [],
   "source": [
    "# Main execution\n",
    "api_key = \"bdeb3ff82ab3c66f2774733873ca1741\"   # Replace with your API key\n",
    "city = \"London\"  # Replace with desired city\n",
    "bucket_name = \"group1lab-03\"  # Replace with your S3 bucket name\n",
    "file_name = \"weather_data.json\"\n",
    "\n",
    "try:\n",
    "    weather_data = get_weather_data(city, api_key)\n",
    "    upload_to_s3(bucket_name, file_name, weather_data)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0O_jA3tBCVJY"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WlFDrpu_Co3T",
    "outputId": "62eba14a-296a-4d75-b03c-4506d47983fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coord': {'lon': -0.1257, 'lat': 51.5085}, 'weather': [{'id': 311, 'main': 'Drizzle', 'description': 'drizzle rain', 'icon': '09n'}, {'id': 500, 'main': 'Rain', 'description': 'light rain', 'icon': '10n'}], 'base': 'stations', 'main': {'temp': 281.7, 'feels_like': 281.1, 'temp_min': 279.61, 'temp_max': 283.98, 'pressure': 1005, 'humidity': 93}, 'visibility': 3200, 'wind': {'speed': 1.54, 'deg': 230}, 'rain': {'1h': 0.67}, 'clouds': {'all': 100}, 'dt': 1701038226, 'sys': {'type': 2, 'id': 2075535, 'country': 'GB', 'sunrise': 1700984164, 'sunset': 1701014381}, 'timezone': 0, 'id': 2643743, 'name': 'London', 'cod': 200}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "api_key = \"bdeb3ff82ab3c66f2774733873ca1741\"  # Replace with your actual API key\n",
    "city = \"London\"\n",
    "try:\n",
    "    weather_data = get_weather_data(city, api_key)\n",
    "    print(weather_data)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Groups to Convert JSON to CSV\n",
    "\n",
    "Step 1. Take the JSON output and convert it to a Dataframe using pandas\n",
    "Step 2. Now upload the CSV file to the 'lab-03' S3 bucket in the cloud with the following naming convention: <your group name>_weather_date_london_<datetimestamp>.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File weather_2023_11_26_london.csv uploaded successfully to bucket group1lab-03.\n"
     ]
    }
   ],
   "source": [
    "###### INSERT CODE BELOW ####\n",
    "\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def upload_csv_s3(bucket_name, file_name, session):\n",
    "    s3 = session.client('s3')\n",
    "    try:\n",
    "        with open(file_name, 'rb') as f:\n",
    "            s3.upload_fileobj(f, bucket_name, file_name)\n",
    "        print(f\"File {file_name} uploaded successfully to bucket {bucket_name}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"File upload to S3 failed. Error: {e}\")\n",
    "\n",
    "# Load AWS credentials\n",
    "with open('C:/Users/msi/OneDrive/Documents/GitHub/aws_credentials.json', 'r') as file:\n",
    "    credentials = json.load(file)\n",
    "\n",
    "# Create a session using your AWS credentials\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=credentials['AWS_ACCESS_KEY_ID'],\n",
    "    aws_secret_access_key=credentials['AWS_SECRET_ACCESS_KEY']\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.json_normalize(weather_data)\n",
    "\n",
    "# Save to CSV\n",
    "date_str = datetime.now().strftime('%Y_%m_%d') #Date\n",
    "file_name = f'weather_{date_str}_london.csv'\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "# Upload to S3 upload_csv_s3\n",
    "bucket_name = 'group1lab-03'\n",
    "upload_csv_s3(bucket_name, file_name, session)\n",
    "\n",
    "\n",
    "### END CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
